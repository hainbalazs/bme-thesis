{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "plain-semester",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import aix360.algorithms.rbm\n",
    "from aix360.algorithms.rbm import FeatureBinarizer\n",
    "from aix360.algorithms.rbm import BooleanRuleCG\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# ignore warning related to deprecated modules inside packages\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "# train with fixed seed to eliminate different results\n",
    "np.random.seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "parliamentary-harrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../datasets/Placement_Data_Full_Class.csv\",\n",
    "                    dtype={\"sl_no\": int,\n",
    "                            \"gender\": 'category',\n",
    "                            \"ssc_p\" : float,\n",
    "                            \"ssc_b\" : 'category',\n",
    "                            \"hsc_p\" : float,\n",
    "                            \"hsc_b\" : 'category',\n",
    "                            \"hsc_s\" : 'category',\n",
    "                            \"degree_p\" : float,\n",
    "                            \"degree_t\" : 'category',\n",
    "                            \"workex\" : 'category',\n",
    "                            \"etest_p\" : float,\n",
    "                            \"specialisation\" : 'category',\n",
    "                            \"mba_p\" : float,\n",
    "                            \"status\" : 'category',\n",
    "                            \"salary\" : float\n",
    "                           })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eleven-flesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['salary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "embedded-softball",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['gender', 'ssc_b', 'hsc_b', 'hsc_s', 'degree_t', 'workex', 'specialisation']\n",
    "fb = FeatureBinarizer(colCateg=categorical_features, negations=True, returnOrd=True)\n",
    "\n",
    "X = data.drop(columns=[\"sl_no\", \"status\"])\n",
    "X_bin, X_std = fb.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "according-transport",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data[\"status\"].map(lambda x: 1 if x == \"Placed\" else 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "placed-administration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_with_BRCG(X, y, CNF=False, lambda0=1e-1, lambda1=1e-2, verbose=True):\n",
    "    # Instantiate BRCG with small complexity penalty\n",
    "    br_model = BooleanRuleCG(lambda0, lambda1, CNF=False)\n",
    "    # Train, print, and evaluate model\n",
    "    br_model.fit(X, y)\n",
    "    if verbose:\n",
    "        print('Training accuracy:', metrics.accuracy_score(y, br_model.predict(X)))\n",
    "    if br_model.CNF:\n",
    "        print('Predict Y=0 if ANY of the following rules are satisfied, otherwise Y=1:')\n",
    "    else:\n",
    "        print('Predict Y=1 if ANY of the following rules are satisfied, otherwise Y=0:')\n",
    "    print(br_model.explain()['rules'])\n",
    "    return br_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "killing-burns",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(by=\"status\").size()[\"Placed\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-arena",
   "metadata": {},
   "source": [
    "# Subtracting dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "short-synthetic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning DNF rule with complexity parameters lambda0=0.01, lambda1=0.01\n",
      "Initial LP solved\n",
      "Iteration: 1, Objective: 0.2060\n",
      "Iteration: 2, Objective: 0.1946\n",
      "Iteration: 3, Objective: 0.1881\n",
      "Training accuracy: 0.8418604651162791\n",
      "Predict Y=1 if ANY of the following rules are satisfied, otherwise Y=0:\n",
      "['ssc_p > 58.00 AND hsc_p > 52.00']\n"
     ]
    }
   ],
   "source": [
    "rules_s = explain_with_BRCG(X_bin, Y, lambda0=0.01, lambda1=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bearing-empty",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_filter = pd.DataFrame(columns=data.columns)\n",
    "\n",
    "for i, sample in X_bin.iterrows():\n",
    "    if(rules_s.predict(sample) == 1):\n",
    "        first_filter.loc[i] = data.loc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "grand-gambling",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = []\n",
    "for i, row in data.iterrows():\n",
    "    if i in first_filter.index:\n",
    "        Y.append(1)\n",
    "    else:\n",
    "        Y.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "prepared-encyclopedia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-leather",
   "metadata": {},
   "source": [
    "# Figuring out which lambda is which"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "prescribed-hours",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def create_confusion_matrix(y, y_pred, title_name=\"\"):\n",
    "    conf_matrix = confusion_matrix(y, y_pred)\n",
    "    grid_label = ['True Negative','False Positive','False Negative','True Positive']\n",
    "    grid = []\n",
    "    for i, count in enumerate(conf_matrix.flatten()):\n",
    "        count_str = f'samples: {count:.0f}'\n",
    "        percentages = f'{count/len(y) * 100:.2f}%'\n",
    "        grid.append(f'{grid_label[i]}\\n{count_str}\\n{percentages}')\n",
    "    grid = np.asarray(grid).reshape(2,2)\n",
    "    conf_matrix = pd.DataFrame(conf_matrix,\n",
    "    columns=[\"might stay\", \"might find a new job\"],\n",
    "    index=[\"will stay\", \"will find a new job\"])\n",
    "    ax = sns.heatmap(conf_matrix, annot=grid, fmt='', cmap='Reds', cbar=False)\n",
    "    ax.set_title(f\"{title_name}\\nConfusion matrix\", pad=40, fontsize=17)\n",
    "    ax.xaxis.set_ticks_position('top')\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "chinese-cornwall",
   "metadata": {},
   "outputs": [],
   "source": [
    "## elso jo parameter:\n",
    "l0 = 0.00000000001\n",
    "l1 = 0.000005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "golden-burning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning DNF rule with complexity parameters lambda0=1, lambda1=1e-13\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'list' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-c277918828f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrules_l0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplain_with_BRCG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_bin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0000000000001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-ed50094783d8>\u001b[0m in \u001b[0;36mexplain_with_BRCG\u001b[0;34m(X, y, CNF, lambda0, lambda1, verbose)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbr_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBooleanRuleCG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambda0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCNF\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Train, print, and evaluate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mbr_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbr_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/AIX360/aix360/algorithms/rbm/boolean_rule_cg.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# Positive (y = 1) and negative (y = 0) samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mnP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'list' and 'float'"
     ]
    }
   ],
   "source": [
    "rules_l0 = explain_with_BRCG(X_bin, Y, lambda0=1, lambda1=0.0000000000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-prescription",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_confusion_matrix(Y, rules_l0.predict(X_bin))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuzzy-fireplace",
   "metadata": {},
   "source": [
    "# Filtering data according to the ruleset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-window",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rules_l0.predict(X_bin.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-plymouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_filter = pd.DataFrame(columns=data.columns)\n",
    "first_filter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-subdivision",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample in X_bin.iterrows():\n",
    "    if(rules_l0.predict(sample) == 1):\n",
    "        first_filter.loc[i] = data.loc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-april",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-bottom",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tired-jackson",
   "metadata": {},
   "source": [
    "# Binarizing the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-capacity",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = first_filter.drop(columns=[\"sl_no\", \"status\"])\n",
    "X1_bin, X1_std = fb.fit_transform(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-temperature",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1 = first_filter[\"status\"].map(lambda x: 1 if x == \"Placed\" else 0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-onion",
   "metadata": {},
   "source": [
    "# Calculating the second layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-pontiac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rules_l1 = explain_with_BRCG(X1_bin, Y1, lambda0=0.0000001, lambda1=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-wyoming",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_confusion_matrix(Y1, rules_l1.predict(X1_bin))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banner-moisture",
   "metadata": {},
   "source": [
    "# Building a framework for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-queue",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NestedCavities:\n",
    "    def __init__(self, dataset, cat_list, drop_list, target_n, target_v, l1_null, l1_inf, l2_init, l2_rate, max_iter):\n",
    "        self.df = dataset\n",
    "        self.categories = cat_list\n",
    "        self.to_drop = drop_list\n",
    "        self.target_n = target_n\n",
    "        self.target_v = target_v\n",
    "        self.l1_bot = l1_null\n",
    "        self.l1_top = l1_inf\n",
    "        self.l2 = l2_init\n",
    "        self.l2_rate = l2_rate\n",
    "        self.max_iter = max_iter\n",
    "        \n",
    "        \n",
    "    def process(self, data, cat_list, drop_list, target_n, target_v, pos):\n",
    "        fb = FeatureBinarizer(colCateg=cat_list, negations=True, returnOrd=True)\n",
    "        X = data.drop(columns=drop_list)\n",
    "        X_bin, X_std = fb.fit_transform(X)\n",
    "        \n",
    "        if pos:\n",
    "            Y = data[target_n].map(lambda x: 1 if x == target_v else 0).astype(int)\n",
    "        else:\n",
    "            Y = data[target_n].map(lambda x: 1 if x != target_v else 0).astype(int)\n",
    "        return X_bin, Y\n",
    "        \n",
    "    def fit_cavity(self, bin_v, target_v, l0, l1):\n",
    "        \n",
    "        br_model = BooleanRuleCG(l0, l1, CNF=False)\n",
    "        # Train, print, and evaluate model\n",
    "        br_model.fit(bin_v, target_v)\n",
    "        return br_model\n",
    "    \n",
    "    def filter_data(self, dataset, bin_v, rules, pos):\n",
    "\n",
    "        target = 1 if pos else 0\n",
    "        filtered_df = pd.DataFrame(columns=dataset.columns)\n",
    "        \n",
    "        for i, sample in bin_v.iterrows():\n",
    "            if(rules.predict(sample) == target):\n",
    "                filtered_df.loc[i] = dataset.loc[i]\n",
    "                \n",
    "        return filtered_df\n",
    "    \n",
    "    def subtract_rules(self, ruleset, neg_rules):\n",
    "        pass\n",
    "    \n",
    "    def good_enough(self, prev_set, current_set, n_iter):\n",
    "        # gondolkodni kell rajta:\n",
    "        \"\"\"\n",
    "        - detektalni mikor ugyanazt rakjuk ki es be\n",
    "          - osszevetni az elozo iteracioval az eredmeny halmazt, ha ugyanaz vege\n",
    "        - osszes eredetileg pozitivkent jelolt mintat kivalasztottuk (valoszinuleg tulilleszt)\n",
    "          - szamoljuk meg az algoritmus elejen hany pozitiv van\n",
    "          - ha annyi pozitiv van a mi halmazunkban, es az osszes pozitiv akkor vege\n",
    "        - szabalyok komplexitasara megkotes?\n",
    "          - szabalyok komplexitasa ~ aix\n",
    "        \"\"\"\n",
    "        \n",
    "        if n_iter == self.max_iter or current_set.equals(prev_set):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def evaluate(self, filtered_data):\n",
    "        Y_pred = []\n",
    "        for i, row in self.df.iterrows():\n",
    "            if i in filtered_data.index:\n",
    "                Y_pred.append(1)\n",
    "            else:\n",
    "                Y_pred.append(0)\n",
    "        \n",
    "        Y_org = self.df[self.target_n].map(lambda x: 1 if x == self.target_v else 0).astype(int)\n",
    "        stats = [] \n",
    "        conf_matrix = confusion_matrix(Y_org, Y_pred)\n",
    "        for i, count in enumerate(conf_matrix.flatten()):\n",
    "            stats.append(count)\n",
    "            \n",
    "        return (stats, len(Y_org))\n",
    "    \n",
    "    def rule_complexity(self, rules):\n",
    "        c = 0\n",
    "        for rule in rules:\n",
    "            c += self.l2 \n",
    "            for term in rule:\n",
    "                c += self.l1_top \n",
    "                \n",
    "        return c\n",
    "            \n",
    "    \n",
    "    def learn(self):\n",
    "        ruleset = []\n",
    "        conf_stats = []\n",
    "        prev_samples = pd.DataFrame()\n",
    "        pos_class_samples = pd.DataFrame(columns=self.df.columns)\n",
    "        data = self.df\n",
    "        n_iter = 0\n",
    "        while not self.good_enough(prev_samples, pos_class_samples, n_iter):\n",
    "            # getting all the positives + some false positives\n",
    "            tr_X, tr_Y = self.process(data, self.categories, self.to_drop, self.target_n, self.target_v, True)\n",
    "            \n",
    "            if tr_Y.sum() == 0:\n",
    "                print(\"No more positive samples found among the remaining samples I.\")\n",
    "                print(f\"Phase {n_iter} / I.\")\n",
    "                break\n",
    "            rules = self.fit_cavity(tr_X, tr_Y, self.l2, self.l1_top)\n",
    "            filtered_data = self.filter_data(data, tr_X, rules, True)\n",
    "            \n",
    "            ruleset += rules.explain()['rules']\n",
    "            print(\"Compound rule complexity\")\n",
    "            print(self.rule_complexity(ruleset))\n",
    "            \n",
    "            # removing all the negatives + some false negatives\n",
    "            tr_X, tr_Y = self.process(filtered_data, self.categories, self.to_drop, self.target_n, self.target_v, False)\n",
    "            if tr_Y.sum() == 0:\n",
    "                print(\"No more positive samples found among the remaining samples.\")\n",
    "                print(f\"Phase {n_iter} / II.\")\n",
    "                break\n",
    "            rules = self.fit_cavity(tr_X, tr_Y, self.l2, self.l1_top)\n",
    "            print(\"Selector rule complexity\")\n",
    "            print(self.rule_complexity(rules.explain()['rules']))\n",
    "            \n",
    "            filtered_data2 = self.filter_data(filtered_data, tr_X, rules, False)\n",
    "            removed_data = self.filter_data(filtered_data, tr_X, rules, True)\n",
    "            \n",
    "            self.subtract_rules(ruleset, rules)\n",
    "            \n",
    "            # end of the iteration\n",
    "            prev_samples = pos_class_samples\n",
    "            pos_class_samples = pd.concat([pos_class_samples, filtered_data2])\n",
    "            self.l2 *= self.l2_rate\n",
    "            data = removed_data\n",
    "            conf_stats.append(self.evaluate(pos_class_samples))\n",
    "            n_iter += 1\n",
    "                \n",
    "        return pos_class_samples, ruleset, conf_stats\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-zimbabwe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_list = ['gender', 'ssc_b', 'hsc_b', 'hsc_s', 'degree_t', 'workex', 'specialisation']\n",
    "drop_list = [\"sl_no\", \"status\", \"salary\"]\n",
    "target_n = \"status\"\n",
    "target_v = \"Placed\"\n",
    "# egyelőre..\n",
    "l1_null = None\n",
    "l1_inf = 0.000005\n",
    "l2_init = 0.00000000001\n",
    "l2_rate = 0.1\n",
    "max_iter = 10\n",
    "nc = NestedCavities(data, cat_list, drop_list, target_n, target_v, l1_null, l1_inf, l2_init, l2_rate, max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painful-harrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_class_samples, _, conf_stats = nc.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-poland",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
